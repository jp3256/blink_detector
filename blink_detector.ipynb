{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "blink_detector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPy/KynWSDEQDhSu2zdIQn7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jp3256/blink_detector/blob/main/blink_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYjHK6VdssIY",
        "outputId": "890a1174-5edd-467f-ac85-30cd99f3c139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# connect to google drive folder\n",
        "from google.colab import drive\n",
        "import glob\n",
        "drive.mount('/content/drive')\n",
        "file_directory1 = '/content/drive/My Drive/Applied Research/data/final_study/batch1/'\n",
        "file_directory2 = '/content/drive/My Drive/Applied Research/data/final_study/batch2/'\n",
        "file_directory3 = '/content/drive/My Drive/Applied Research/data/final_study/batch3/'\n",
        "landmark_predictor_directory = '/content/drive/My Drive/Applied Research/data/shape_predictor_68_face_landmarks.dat'\n",
        "\n",
        "# import the necessary packages\n",
        "from scipy.spatial import distance as dist\n",
        "from imutils.video import FileVideoStream\n",
        "from imutils import face_utils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import imutils\n",
        "import time\n",
        "import dlib\n",
        "import cv2\n",
        "import re\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TghEAUUDwCVE"
      },
      "source": [
        "# function to calculate eye aspect ratio\n",
        "def eye_aspect_ratio(eye):\n",
        "    # vertical distance between eye landmark coordinates\n",
        "    vertical1 = dist.euclidean(eye[1], eye[5])\n",
        "    vertical2 = dist.euclidean(eye[2], eye[4])\n",
        "\n",
        "    # horizontal distance between eye landmark coordinates\n",
        "    horizontal = dist.euclidean(eye[0], eye[3])\n",
        "\n",
        "    # compute the eye aspect ratio\n",
        "    eye_aspect_ratio = (vertical1 + vertical2) / (2.0 * horizontal)\n",
        "\n",
        "    return eye_aspect_ratio"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqr-e0RoF-Ii"
      },
      "source": [
        "# function to get number of blinks\n",
        "# code reference: https://www.pyimagesearch.com/2017/04/24/eye-blink-detection-opencv-python-dlib/\n",
        "def get_num_blinks(video_path):\n",
        "    # start video stream thread\n",
        "    vs = FileVideoStream(video_path).start()\n",
        "    time.sleep(1.0)\n",
        "    stop = False\n",
        "    frame_count = 0\n",
        "    total_blinks = 0\n",
        "    # loop over frames\n",
        "    while stop==False:\n",
        "        # check if there are more frames to process\n",
        "        if vs.more():\n",
        "            # get frame from video file stream\n",
        "            frame = vs.read()\n",
        "            if frame is not None:\n",
        "                # resize frame\n",
        "                frame = imutils.resize(frame, width=450)\n",
        "                # convert to grayscale\n",
        "                grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "                # detect face\n",
        "                face_rectangle = face_detector(grayframe, 0)\n",
        "                for rect in face_rectangle:\n",
        "                    # detect facial landmarks\n",
        "                    shape = landmark_predictor(grayframe, rect)\n",
        "                    # convert facial landmark (x, y)-coordinates to numpy array\n",
        "                    shape = face_utils.shape_to_np(shape)\n",
        "                    # get left and right eye coordinates\n",
        "                    left_eye = shape[l_start:l_end]\n",
        "                    right_eye = shape[r_start:r_end]\n",
        "                    # calculate EAR for both eyes and average them\n",
        "                    left_ear = eye_aspect_ratio(left_eye)\n",
        "                    right_ear = eye_aspect_ratio(right_eye)\n",
        "                    average_ear = (left_ear + right_ear) / 2.0\n",
        "                    # draw contours around each eye by computing the convex hull \n",
        "                    left_eye_hull = cv2.convexHull(left_eye)\n",
        "                    right_eye_hull = cv2.convexHull(right_eye)\n",
        "                    cv2.drawContours(frame, [left_eye_hull], -1, (255, 0, 0), 1)\n",
        "                    cv2.drawContours(frame, [right_eye_hull], -1, (255, 0, 0), 1)\n",
        "                    # if EAR < blink threshold, increment frame count\n",
        "                    if average_ear < EAR_THRESHOLD:\n",
        "                        frame_count += 1\n",
        "                    else:\n",
        "                        # if eyes were closed for NUM_CONSEC_FRAMES, increment total blinks\n",
        "                        if frame_count >= NUM_CONSEC_FRAMES:\n",
        "                            total_blinks += 1\n",
        "                        # reset frame counter\n",
        "                        frame_count = 0\n",
        "                    # # display total number of blinks and EAR on the frame\n",
        "                    # cv2.putText(frame, \"# Blinks: {}\".format(total_blinks), (10, 30),\n",
        "                    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "                    # cv2.putText(frame, \"EAR: {:.2f}\".format(average_ear), (300, 30),\n",
        "                    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "            else:\n",
        "                stop = True\n",
        "            # # show the frame\n",
        "            # cv2_imshow(frame)\n",
        "    # end\n",
        "    cv2.destroyAllWindows()\n",
        "    vs.stop()\n",
        "    return total_blinks"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwwELJY4wzX7"
      },
      "source": [
        "# define hyperparameters (EAR threshold, # consecutive frames < EAR threshold)\n",
        "EAR_THRESHOLD = 0.25\n",
        "NUM_CONSEC_FRAMES = 3\n",
        "\n",
        "# initialize dlib face detector (HOG-based) & facial landmark predictor (pre-trained)\n",
        "face_detector = dlib.get_frontal_face_detector()\n",
        "landmark_predictor = dlib.shape_predictor(landmark_predictor_directory)\n",
        "\n",
        "# get indexes of facial landmarks for left and right eye\n",
        "(l_start, l_end) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
        "(r_start, r_end) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujW2Mxjq1F-h"
      },
      "source": [
        "file_directories = [file_directory1, file_directory2, file_directory3]\n",
        "# loop through batches\n",
        "for file_directory in file_directories:\n",
        "    print(file_directory)\n",
        "    # compile results\n",
        "    blink_results = []\n",
        "    for file in glob.glob(file_directory+'*.mp4'):\n",
        "        group_number = re.search(r'(?<=batch)([0-9]+)/([0-9]+)', file).group(2)\n",
        "        condition = re.search(r'(?<=batch)([0-9]+)/([0-9]+)(-*)([A-Za-z]+)', file).group(4).lower()\n",
        "        role = re.search(r'(?<=batch)([0-9]+)/([0-9]+)(-*)([A-Za-z]+)(-*)([A-Za-z]+)(-*)([A-Za-z]+)*', file).group(8)\n",
        "        number_blinks = get_num_blinks(file)\n",
        "        blink_results.append({'group_number': group_number,\n",
        "                        'condition': condition,\n",
        "                        'role': role,\n",
        "                        'number_blinks': number_blinks})\n",
        "        print(group_number)\n",
        "    df = pd.DataFrame(blink_results)\n",
        "    df.to_csv(file_directory + 'batch_results_ear_0_25_3frames.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rYLuPS9i1PG"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}